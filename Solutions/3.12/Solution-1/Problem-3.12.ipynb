{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quicksort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to the Analysis of Algorithms (3rd ed)\n",
    "##### Michael Soltys\n",
    "\n",
    "##### Notebook by Ryan McIntyre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have the quicksort method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quicksort(input_list):\n",
    "    if len(input_list) <= 1:\n",
    "        return input_list\n",
    "    else:\n",
    "        x = input_list.pop()\n",
    "        small = []\n",
    "        large = []\n",
    "        for a in A:\n",
    "            if a <= x:\n",
    "                small.append(a)\n",
    "            else:\n",
    "                large.append(a)\n",
    "        return quicksort(small) + [x] + quicksort(large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume input_list has $n$ elements. Clearly, the recursive depth is at most $n$ in the worst case. On a call at depth $i$, there are $n-i$ elements which have not been \"isolated\" (i.e. chosen to be the pivot, called $x$ above), and moreover these elements are partitioned into the calls at depth $i$. This grants that at depth $i$ there are at most $n-i$ comparisons overall. This provides an easy upper bound; quicksort is $O(n^2)$.\n",
    "\n",
    "On the other hand, in the best-case scenario, the algorithm chooses a median (after sorting) for the pivot, so the input lists for the next calls have cardinalities $\\lceil\\frac{n-1}{2}\\rceil$ and $\\lfloor\\frac{n-1}{2}\\rfloor$. In other words, they are approximately half as large as the input list. In this best case, $T(n)=2T(n/2)+n$, where the trailing $n$ is the \"for\" loop defining the initial partition. \n",
    "\n",
    "Identically, $T(n)=2T(2^{\\log{n}-1})+n$. Let $s=\\log{n}$. We have \n",
    "$$\n",
    "T(2^s)=2T(2^{s-1})+2^s\n",
    "$$ \n",
    "Let $T'(s)$ be the sequence defined by $T(2^s)$ for $s\\in\\{1,2,\\dots\\}$. Clearly,\n",
    "$$\n",
    "T'(s)=2T'(s-1)+2^s\n",
    "$$\n",
    "\n",
    "Choose $t=T'(0)$. Let's expaned the first few values of $T'$:\n",
    "$$\n",
    "T'(1)=2(t+1)\n",
    "$$\n",
    "$$\n",
    "T'(2)=2(2t+2)+2^2=4t+8=2^2(t+2)\n",
    "$$\n",
    "$$\n",
    "T'(3)=2(4t+8)+2^3=8t+24=2^3(t+3)\n",
    "$$\n",
    "$$\n",
    "T'(4)=2(8t+24)+2^4=16t+64=2^4(t+4)\n",
    "$$\n",
    "$$\n",
    "...\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an easy guess, displayed in the last representation of each equation above: $T'(s)=2^s(t+s)$. Our base case is above, so we aim to prove this recursion by induction. Assume that it is true for some $s$. Then $T'(s+1)=2T'(s)+2^s=2^{s+1}(t+s)+2^{s+1}=2^{s+1}(t+s+1)$. We have proven inductively that $T'(s)=2^s(t+s)$. Identically, $T(n)=n(t+\\log{n})$, so $T(n)$ is $O(n\\log{n})$.\n",
    "\n",
    "For average complexity, our task is a bit more complicated. We'll assume, to simplify the problem slightly, that all of the elements of the input list are unique, so there is a unique non-decreasing ordering. Under this assumption, the size of the larger partition follows a uniform distribution, over the integers ranging, incrementing by 1, in $C=\\{\\lceil\\frac{n-1}{2}\\rceil,\\dots,n-1\\}$.\n",
    "\n",
    "Let $c\\in C$ be the ratio of the size of the larger partition to that of the input on a given iteration. We get an \"average\" recurrence, similar to the one above: $A(n)=A(cn)+A((1-c)n)+n$. Note that $A(n)\\le2A(cn)+n$. So, replacing all of the $\\log$s (which were by default base 2) above with $\\log_c$ and following the same route would lead to: $A(n)\\le n(t+\\log_c{n})$; we have not found the average complexity, but we have shown that it is $O(n\\log_c{n})$. Moreover, $\\log_c{n}=\\frac{\\log{n}}{\\log{c}}$ (where the actual \"average\" for the possible $c$'s would be the geometric mean of $C$) so $A(n)$ is $O(n\\log n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we choose the pivot slightly more carefully, we can greatly improve our chances of finding a \"good\" pivot (i.e., one near the median value). An effective method for choosing the pivot is provided by the Median-of-three method. Initially, select 3 elements from the list. Theoretically it doesn't matter which three are chosen, but conventionally the first, median (in the current ordering), and last elements are selected. We then sort these three, let the middle be the pivot and add the other two to the $smaller$ and $larger$ lists. This guarantees that at least 1 element is in the smaller partition, reducing worst-case recursion depth to $n-1$. Of course, it also requires the addition of a second \"base case\" in the algorithm itself, to account for the case where the length of the list is $2$."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
