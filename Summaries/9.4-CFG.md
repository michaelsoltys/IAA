# Context-Free Languages Summary (Section 9.4)

## Introduction

Context-free grammars originated from Noam Chomsky's work on defining a "generative" grammar for English language syntax. While not fully successful in linguistics, this approach had tremendous impact in Computer Science by providing techniques to precisely define programming language syntax.

**Historical Impact:**
- ALGOL was the first programming language designed using Chomsky grammars
- Led to development of languages like C, C++, Pascal
- Introduced indentation for program readability

## Context-Free Grammars (CFGs)

### Formal Definition

A **Context-Free Grammar (CFG)** is a 4-tuple: **G = (V, T, P, S)**

Where:
- **V**: Set of variables (non-terminals)
- **T**: Set of terminals 
- **P**: Set of productions (rules)
- **S**: Start variable

### Key Examples

#### 1. Palindromes Grammar
```
P → ε | 0 | 1 | 0P0 | 1P1
```
This grammar generates all palindromes over {0,1}.

#### 2. Algebraic Expressions Grammar
```
G = ({E,T,F}, {a,+,×,(,)}, P, E)

Productions:
E → E+T | T
T → T×F | F  
F → (E) | a
```

**Structural interpretation:**
- **E (Expression)**: A term or sum of expression and term
- **T (Term)**: A factor or product of term and factor  
- **F (Factor)**: Parenthesized expression or terminal 'a'

### Core Concepts

#### Derivations
- **αAβ ⇒ αγβ**: String αAβ yields αγβ using production A → γ
- **⇒\***: Zero or more derivation steps
- **L(G) = {w ∈ T* | S ⇒* w}**: Language of grammar G

#### Types of Derivations
1. **Recursive inference**: Generate derivation from w to S
2. **Left-most derivation**: Always apply rule to leftmost variable
3. **Right-most derivation**: Always apply rule to rightmost variable
4. **Parse tree yield**: Tree-based representation

#### Sentential Forms
- **Sentential form**: Any string α where S ⇒* α
- **Language L(G)**: Set of sentential forms that are in T*

### Parse Trees

**Structure:**
- Root labeled with start symbol S
- Leaves labeled left-to-right with symbols of w
- Interior nodes follow pattern: A → X₁X₂...Xₙ

### Ambiguity

A grammar is **ambiguous** if some words have multiple parse trees.

**Example of ambiguous grammar:**
```
G = ({E}, [0-9], {E → E+E, E → E*E}, E)

Two different parse trees for same expression:
E ⇒ E+E ⇒ E+E*E
E ⇒ E*E ⇒ E+E*E
```

**Problem**: Different parse trees assign different meanings to the same string.

## Pushdown Automata (PDAs)

### Motivation
- PDAs are the computational model corresponding to CFGs
- Equivalent to DFAs for regular languages, but with stack memory
- Represents 1960s hardware-oriented thinking in Computer Science

### Formal Definition

A **Pushdown Automaton (PDA)** is: **P = (Q, Σ, Γ, δ, q₀, F)**

Where:
- **Q**: Finite set of states
- **Σ**: Finite input alphabet  
- **Γ**: Finite stack alphabet
- **δ(q,x,a) = {(p₁,b₁),...,(pₙ,bₙ)}**: Transition function
- **q₀**: Initial state
- **F**: Set of accepting states

### PDA Operation

#### Configuration
A **configuration** is a tuple **(q, w, γ)**:
- **q**: Current state
- **w**: Remaining input
- **γ**: Stack contents

#### Transition
If **(p,α) ∈ δ(q,a,X)**, then:
**(q, aw, Xβ) ⊢ (p, w, αβ)**

### Acceptance Methods

#### 1. Acceptance by Final State
```
L(P) = {w | (q₀, w, $) ⊢* (q, ε, α), q ∈ F}
```

#### 2. Acceptance by Empty Stack  
```
L(P) = {w | (q₀, w, $) ⊢* (q, ε, ε)}
```

**Important**: Both methods are equivalent and capture the same set of languages.

### Example: Palindromes PDA

For grammar P → ε | 0 | 1 | 0P0 | 1P1:

**Transitions:**
```
δ(q₀, ε, $) = {(q, P$)}
δ(q, ε, P) = {(q, 0P0), (q, 0), (q, ε), (q, 1P1), (q, 1)}
δ(q, 0, 0) = δ(q, 1, 1) = {(q, ε)}
δ(q, 0, 1) = δ(q, 1, 0) = ∅
δ(q, ε, $) = (q, ε)
```

## CFG-PDA Equivalence

### Theorem
**Context-Free Grammars and Pushdown Automata are equivalent.**

### CFG → PDA Construction

**Key idea**: Use **left sentential forms**
- Configuration: x A α where x ∈ T*, A α is "tail" 
- Stack contains the tail
- x is consumed input prefix
- Input w = xy where A α ⇒* y

**Process:**
1. Parse initial segment of β from rule A → β
2. Compare terminals against input and remove them
3. Expose first variable of β on stack top
4. Repeat until acceptance by empty stack

### PDA → CFG Construction

**Key idea**: **"Net popping"** of stack symbols while consuming input

**Variables**: A[pXq] for p,q ∈ Q, X ∈ Γ
- A[pXq] ⇒* w iff w takes PDA from state p to state q and pops X

**Productions:**
- For all p: S → A[q₀$p]  
- For (r, Y₁Y₂...Yₖ) ∈ δ(q,a,X):
  ```
  A[qXrₖ] → a A[rY₁r₁] A[r₁Y₂r₂] ... A[rₖ₋₁Yₖrₖ]
  ```

## Key Takeaways

1. **CFGs provide formal syntax definition** for programming languages
2. **Parse trees assign meaning** to strings through structural representation  
3. **Ambiguity is problematic** - multiple meanings for same string
4. **PDAs are equivalent to CFGs** - two views of same computational power
5. **Stack memory enables context-free recognition** beyond regular languages
6. **Both acceptance methods** (final state vs. empty stack) are equivalent