\input{slides-common.tex}
\newcommand{\mytitle}{Linera Algebra / Parallel}
\newcommand{\mychpnr}{7}
\input{slides-title.tex}

\section{Introduction}

%\addfootbox{\tiny}

\section{Gaussian Elimination}

\begin{frame}
\frametitle{Row-echelon form}

$$
\left[\begin{array}{cccccccc}
1 & *\ldots * & * & *\ldots * & * & *\ldots * & * & \\
  &           & 1 & *\ldots * & * & *\ldots * & * & \\
  &  \ddots   &   &           & 1 & *\ldots * & * & \\
  &           & 0 &           &   &           & 1 & \ldots \\
  &           &   &  \ddots   &   &           & \vdots & \ddots
\end{array}\right]
$$
\end{frame}

\begin{frame}
\frametitle{Elementary matrices}

one of the following three forms:
\begin{align*}
& I+aT_{ij} \quad i\neq j        \tag{elementary of type 1} \\
& I+T_{ij}+T_{ji}-T_{ii}-T_{jj}  \tag{elementary of type 2} \\
& I+(c-1)T_{ii} \quad c\neq 0    \tag{elementary of type 3}
\end{align*} 
\end{frame}

\begin{frame}
Gaussian Elimination is a divide and conquer algorithm,
with a recursive call to smaller matrices.

If $A$ is a $1\times m$ matrix, $A=[a_{11} a_{12} \ldots a_{1m}]$,
then:
$$
GE(A)=\begin{cases}
[1/a_{1i}] & \text{where $i=\min\{1,2,\ldots,m\}$ such that
                   $a_{i1}\neq 0$} \\
[1]        & \text{if $a_{11}=a_{12}=\cdots=a_{1m}=0$}
\end{cases}
$$

Suppose now that $n>1$.  If $A=0$, let $GE(A)=I$.  Otherwise, let:
$$
GE(A)=\left[\begin{array}{cc}
1 & 0 \\
0 & GE((EA)[1|1])
\end{array}\right]E
$$
where $E$ is a product of at most $n+1$ elementary matrices.
Note that $C[i|j]$ denotes the matrix $C$ with row $i$ and $j$.
\end{frame}

\begin{frame}
\begin{algorithmic}[1]
\IF {$n=1$}
	\IF {$a_{11}=a_{12}=\cdots=a_{1m}=0$}
		\RETURN $[1]$
	\ELSE
		\RETURN $[1/a_{1\ell}]$ where $\ell=\min_{i\in [n]}\{a_{1i}\neq 0\}$
	\ENDIF
\ELSE
	\IF {$A=0$}
		\RETURN $I$
	\ELSE
		\IF {first column of $A$ is zero}
			\STATE Compute $E$ as in Case 1.
		\ELSE
			\STATE Compute $E$ as in Case 2.
		\ENDIF
		\RETURN $\left[\begin{array}{cc}
						1 & 0 \\
						0 & GE((EA)[1|1])
						\end{array}\right]E$
	\ENDIF
\ENDIF 
\end{algorithmic}

\end{frame}

\section{Gram-Schmidt}

\begin{frame}
\frametitle{Gram-Schmidt}

\begin{algorithmic}[1] 
\REQUIRE $\{v_1,\ldots,v_n\}$ a basis for $\mathbb{R}^n$
\STATE $v_1^*\longleftarrow v_1$ 
\FOR{$i=2,3,\ldots,n$} 
     \FOR{$j=1,2,\ldots,(i-1)$} 
          \STATE $\mu_{ij}\longleftarrow (v_i\cdot v_j^*)/\|v_j^*\|^2$ 
     \ENDFOR
     \STATE $v_i^*\longleftarrow v_i-\sum_{j=1}^{i-1}\mu_{ij}v_j^*$
\ENDFOR
\ENSURE $\{v_1^*,\ldots,v_n^*\}$ an orthogonal basis for $\mathbb{R}^n$
\end{algorithmic}
\end{frame}

\section{Guass lattice reduction}

\begin{frame}
\frametitle{Gauss lattice reduction}

\begin{algorithmic}[1]
\REQUIRE $\{v_1,v_2\}$ are linearly independent in $\mathbb{R}^2$
\LOOP
	\IF{$\|v_2\|<\|v_1\|$}
		\STATE swap $v_1$ and $v_2$
	\ENDIF
	\STATE $m\longleftarrow\lfloor v_1\cdot v_2/\|v_1\|^2\rceil$
	       (note that $\lfloor x\rceil=\lfloor x+1/2\rfloor$)
	\IF{$m=0$}
		\RETURN $v_1,v_2$
	\ELSE
		\STATE $v_2\longleftarrow v_2-mv_1$
	\ENDIF
\ENDLOOP
\end{algorithmic}
\end{frame}

\section{Csanky's algorithm}

\begin{frame}
\frametitle{Csanky}

Given a matrix $A$, its {\em trace} is defined as
the sum of the diagonal entries, i.e., $\tr(A)=\sum_ia_{ii}$. Using
traces we can compute the 
{\em Newton's symmetric polynomials} which
are defined as follows: $s_0=1$, and for $1\le k\le n$, by:
$$
s_k=\frac{1}{k}\sum_{i=1}^{k}(-1)^{i-1}s_{k-i}\tr(A^i).
$$
Then, it turns out that $p_A(x)=s_0x^n-s_1x^{n-1}+s_2x^{n-2}-\cdots\pm s_nx^0$,
that is, Newton's symmetric polynomials compute the coefficients of
the characteristic polynomial, $p_A(x)=\det(xI-A)$.
\end{frame}

\begin{frame}
$$
\left(\begin{array}{c} s_1\\s_2\\\vdots\\s_n \end{array}\right),
\quad
\left(\setlength{\extrarowheight}{8pt}\begin{array}{llll}
0                   & 0                   & 0                 & \ldots \\
\frac{1}{2}\tr(A)   & 0                   & 0                 & \ldots \\
\frac{1}{3}\tr(A^2) & \frac{1}{3}\tr(A)   & 0                 & \ldots \\
\frac{1}{4}\tr(A^3) & \frac{1}{4}\tr(A^2) & \frac{1}{4}\tr(A) & \ldots \\
\vdots              & \vdots              & \vdots            & \ddots
\end{array}\right),
\quad
\left(\setlength{\extrarowheight}{8pt}\begin{array}{l} 
\tr(A) \\
\frac{1}{2}\tr(A^2) \\
\vdots \\
\frac{1}{n}\tr(A^n)
\end{array}\right)
$$

\end{frame}

\section{Berkowitz's algorithm}

\begin{frame}
\frametitle{Berkowitz}
Berkowitz's algorithm is also Divide and Conquer, and it computes
the characteristic polynomial of $A$ from the characteristic
polynomial of its {\em principal minor},
i.e., the matrix $M$ obtained from deleting the first row and column
of $A$:
$$
A=\left(\begin{array}{cc}
a_{11} & R \\
S      & M
\end{array}\right),
$$
\end{frame}

\begin{frame}
$R$ is an $1\times(n-1)$ row matrix and $S$ is a $(n-1)\times 1$
column matrix and $M$ is $(n-1)\times(n-1)$.  Let $p(x)$ and $q(x)$ be
the characteristic polynomials of $A$ and $M$ respectively.  Suppose
that the coefficients of $p$ form the column vector: 
$$
p=\left(\begin{array}{cccc}
p_n&p_{n-1}&\ldots&p_0\end{array}\right)^t,
$$
where $p_i$ is the coefficient of $x^i$ in $\det(xI-A)$, and similarly
for $q$.  Then:
$$
p=C_1q,
$$
where $C_1$ is an $(n+1)\times n$ {\em
Toeplitz} lower triangular matrix
(Toeplitz means that the values on each diagonal are constant)
\end{frame}

\begin{frame}
where the entries in the first column are defined as follows:
$c_{i1}=1$ if $i=1$, $c_{i1}=-a_{11}$ if $i=2$, and
$c_{i1}=-(RM^{i-3}S)$ if $i\geq 3$.
Berkowitz's algorithm consists in repeating this for $q$, and
continuing so that $p$ is expressed as a product of matrices.  Thus:
$$
\berk_A=C_1C_2\cdots C_n,
$$
where $C_i$ is an $(n+2-i)\times (n+1-i)$ Toeplitz matrix defined as
above except $A$ is replaced by its $i$-th principal
sub-matrix.  Note that $C_n=(1 \ \  -a_{nn})^t$.
\end{frame}

\end{document}
