\input{slides-common.tex}
\newcommand{\mytitle}{Online}
\newcommand{\mychpnr}{5}
\input{slides-title.tex}

\section{List accessing}

\begin{frame}
{\bf List Accessing}

If a file is in position $i$, we incur a search cost of $i$ in
locating it.  

If the file is not in the cabinet, the cost is $l$, which is the total
number of files. 

Let $\sigma=\sigma_1,\sigma_2,\ldots,\sigma_n$ be a finite sequence of
$n$ requests.  To service request $\sigma_i$, a list accessing
algorithm $\ALG$ must search for the item labeled $\sigma_i$ by
traversing the list from the beginning, until it finds it.  

The cost of retrieving this item is the index of its position on the
list.  Thus, if item $\sigma_i$ is in position $j$, the cost of
retrieving it is $j$.  Furthermore, the algorithm may reorganize the
list at any time. 
\end{frame}

\begin{frame}
The work associated with a reorganization is the minimum number of
transpositions of consecutive items needed to carry it out.  

Each transposition has a cost of~1, however, immediately after
accessing an item, we allow it to be moved free of charge to any
location closer to the front of this list.  

These are {\em free} transpositions, while all other transpositions
are {\em paid}.  

Let $\ALG(\sigma)$ be the sum of the costs of servicing all the items
on the list $\sigma$, i.e., the sum of the costs of all the searches
plus the sum of the costs of all paid transpositions.
\end{frame}

\begin{frame}
Let $\OPT$ be an optimal (offline) algorithm for the static list
accessing model.  

Suppose that $\OPT$ and $\MTF$ both start with the same list
configuration.  Then, for any sequence of requests $\sigma$, where
$|\sigma|=n$, we have that 
$$
\MTF(\sigma)\le 2\cdot\OPT_S(\sigma)+\OPT_P(\sigma)-\OPT_F(\sigma)-n,
$$
where $\OPT_S(\sigma),\OPT_P(\sigma),\OPT_F(\sigma)$ are the total
cost of searches, the total number of paid transpositions and the
total number of free transpositions, of $\OPT$ on $\sigma$, respectively.
\end{frame}

\begin{frame}
Imagine that both $\MTF$ and $\OPT$ process the requests in $\sigma$,
while each algorithm works on its own list, starting from the same
initial configuration.  

You may think of $\MTF$ and $\OPT$ as working
in parallel, starting from the same list, and neither starts to
process $\sigma_i$ until the other is ready to do so.
\end{frame}

\begin{frame}
Let 
$$
a_i=t_i+(\Phi_i-\Phi_{i-1})
$$
where $t_i$ is the actual cost that $\MTF$ incurs for processing this
request (so $t_i$ is in effect the position of item $\sigma_i$ on the
list of $\MTF$ {\em after} the first $i-1$ requests have been
serviced).  

$\Phi_i$ is a {\em potential function}\index{potential
function}, and here it is
defined as the number of {\em inversions} in $\MTF$'s list with respect
to $\OPT$'s list.  

An inversion is defined to be an
ordered pair of items $x_j$ and $x_k$, where $x_j$ precedes $x_k$ in
$\MTF$'s list, but $x_k$ precedes $x_j$ in $\OPT$'s list.  
\end{frame}

\begin{frame}
Note that $\Phi_0$ depends only on the initial configurations of
$\MTF$
and $\OPT$, and since we assume that the lists are initially identical,
$\Phi_0=0$.  

Finally, the value $a_i$ is called
the {\em amortized cost}, and its intended
meaning is the cost of accessing $\sigma_i$, i.e., $t_i$, plus a
measure of the increase of
the ``distance'' between $\MTF$'s list and $\OPT$'s list after processing
$\sigma_i$, i.e., $\Phi_i-\Phi_{i-1}$.
\end{frame}

\begin{frame}
It is obvious that the cost incurred by $\MTF$ in servicing $\sigma$,
denoted $\MTF(\sigma)$, is $\sum_{i=1}^nt_i$.  

But instead of
computing $\sum_{i=1}^nt_i$, which is difficult, we compute
$\sum_{i=1}^na_i$ which is much easier.  

The relationship between the
two summations is,
$$
\MTF(\sigma)=\sum_{i=1}^nt_i=\Phi_0-\Phi_n+\sum_{i=1}^na_i,
$$
and since we agreed that $\Phi_0=0$, and $\Phi_i$ is always positive,
we have that,
$$
\MTF(\sigma)\le\sum_{i=1}^na_i.
$$
So now it remains to compute an upper bound for $a_i$.
\end{frame}

\begin{frame}
Assume that the $i$-th request, $\sigma_i$, is in position $j$ of
$\OPT$, and in position $k$ of $\MTF$ (i.e., this is the position of this
item {\em after} the first $(i-1)$ requests have been completed).  Let
$x$ denote this item.

We are going to show that 
$$
a_i\le (2s_i-1)+p_i-f_i,
$$
where $s_i$ is the search cost incurred by $\OPT$ for accessing request
$\sigma_i$, and $p_i$ and $f_i$ are the paid and free transpositions,
respectively, incurred by $\OPT$ when servicing $\sigma_i$.  
\end{frame}

\begin{frame}
This
shows that
\begin{align*}
\sum_{i=1}^na_i & \le \sum_{i=1}^n((2s_i-1)+p_i-f_i) \\
&= 2(\sum_{i=1}^ns_i)+(\sum_{i=1}^np_i)-(\sum_{i=1}^nf_i)-n \\
&= 2\OPT_S(\sigma)+\OPT_P(\sigma)-\OPT_F(\sigma)-n,
\end{align*}
\end{frame}

\begin{frame}
Two prove our statement in two 
steps: in the first step $\MTF$ makes its move, i.e., moves
$x$ from the $k$-th slot to the beginning of its list, and we
measure the change in the potential function {\em with respect to} the
configuration of the list of $\OPT$ {\em before} $\OPT$ makes its own
moves to deal with the request for $x$.  

In the second step, $\OPT$
makes its move and now we measure the change in the potential function
{\em with respect to} the configuration of the list of $\MTF$ {\em
after} $\MTF$ has completed its handling of the request (i.e., with
$x$ at the beginning of the list of $\MTF$).
\end{frame}

\begin{frame}
\begin{center}
$\MTF$
\begin{tabular}
{|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|}\hline
$\ast$ & $\ast$ && $\ast$ && $x$ &&& \\\hline\end{tabular} \\[5mm]
$\OPT$
\begin{tabular}
{|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|p{4mm}|}\hline
&&& $x$ && $\ast$ & $\ast$ & $\ast$ & \\\hline\end{tabular}
\end{center}

$x$ is in position $k$ in $\MTF$, and in position $j$ in
$\OPT$.  Note that in the figure it appears that $j<k$, but we make no
such assumption in the analysis.  Let $\ast$ denote items located
before $x$ in $\MTF$ but after $x$ in $\OPT$, i.e., the $\ast$
indicate inversions with respect to $x$.  There may be other
inversions involving $x$, namely items which are after $x$ in
$\MTF$ but before $x$ in $\OPT$, but we are not concerned with 
them.
\end{frame}

\begin{frame}
suppose that there are $v$ such $\ast$,
i.e., $v$ inversions of the type represented in the figure.  Then,
there are at least $(k-1-v)$ items that precede $x$ in both list.

But this implies that $(k-1-v)\le (j-1)$, since $x$ is in the $j$-th
position in $\OPT$.  Thus, 
$(k-v)\le j$.
So what happens when $\MTF$ moves $x$ to the front of the list?  In
terms of inversions two things happen: (i)~$(k-1-v)$ new inversions
are created, with respect to $\OPT$'s list, before $\OPT$ itself deals
with the request for $x$.  Also, (ii)~$v$ inversions are eliminated,
again with respect to $\OPT$'s list, before $\OPT$ itself deals with
the request for $x$.
\end{frame}

\begin{frame}
Therefore, the contribution to the amortized cost is:
$$
k+((k-1-v)-v)=2(k-v)-1
\stackrel{(1)}{\le} 2j-1
\stackrel{(2)}{=} 2s-1
$$
where $(1)$ follows from $(k-v)\le j$ shown above, and $(2)$ follows from the
fact that the search cost incurred by $\OPT$ when looking for $x$ is
exactly $j$. 

In the second step of the analysis, $\MTF$ has made its move and
$\OPT$, after retrieving $x$, rearranges its list.
Each paid transposition
contributes~1 to the amortized cost and each free
transposition contributes~$-1$ to the amortized cost.
\end{frame}

\begin{frame}
In the {\em dynamic list accessing model}
we also have {\em insertions}, where the cost of an insertion
is $l+1$---here $l$ is the length of the list---, and {\em deletions},
where the cost of a deletion is the same as the cost of an access,
i.e., the position of the item on the list.  

Our result still holds in the dynamic case.
\end{frame}

\begin{frame}
The {\em infimum} of a subset $S\subseteq\mathbb{R}$ is
the largest element $r$, not necessarily in $S$, such that for all all
$s\in S$, $r\le s$.

We say that an online algorithm is 
{\em $c$-competitive} if there is a
constant $\alpha$ such that for all finite input sequences
$\ALG(\sigma)\le c\cdot\OPT(\sigma)+\alpha$.  

The infimum over the set
of all values $c$ such that $\ALG$ is $c$-competitive is called the
{\em competitive ratio} of $\ALG$ and is
denoted $\mathcal{R}(\ALG)$.
\end{frame}

\begin{frame}
Observe that $\OPT(\sigma)\le n\cdot l$, where $l$ is the length of
the list and $n$ is $|\sigma|$.

$\MTF$ is a $2$-competitive algorithm, and that $\mathcal{R}(\MTF)\le
2-\frac{1}{l}$.

{\em Competitive analysis}: the payoff of an online algorithm is
measured by comparing its performance to that of an {\em optimal
offline algorithm}

Competitive analysis thus falls within the framework of {\em worst
case}\index{worst case} complexity.
\end{frame}

\section{Paging}

\begin{frame}
{\bf Paging}

Consider a two-level {\em virtual memory system}\index{virtual memory
system}:  each level, slow and fast, can store a number of fixed-size
memory units called {\em pages}\index{pages}.  The slow memory stores
$N$ pages, and the fast memory stores $k$ pages, where $k<N$.  The $k$
is usually much smaller than $N$.

Given a request for page $p_i$, the system must make page $p_i$
available in the fast memory.  If $p_i$ is already in the fast memory,
called a {\em hit}\index{hit}, the system need not do anything.
Otherwise, on a {\em miss}\index{miss}, the system incurs a {\em page
fault}\index{page fault}, and must copy the page $p_i$ from the slow
memory to the fast memory.  In doing so, the system is faced with the
following problem: which page to evict from the fast memory to make
space for $p_i$.  In order to {\em minimize} the number of page
faults, the choice of which page to evict must be made wisely.
\end{frame}

\begin{frame}
\begin{center}
\begin{tabular}{ll}
LRU    &  {\em Least Recently Used}      \\
CLOCK  &  {\em Clock Replacement}        \\
FIFO   &  {\em First-In/First-Out}       \\
LIFO   &  {\em Last-In/First-Out}        \\
LFU    &  {\em Least Frequently Used}    \\\hline
LFD    &  {\em Longest Forward Distance} \\
\end{tabular}
\end{center}
\end{frame}

\begin{frame}

{\em Demand paging} algorithms never evict a page from the cache
unless there is a page fault, that is, they never evict preemptively.
All the paging disciplines in the table on the previous slide are
demand paging.  

We consider the {\em page fault model}, where we charge~1 for bringing
a page into the fast memory, and we charge nothing for accessing a
page which is already there. 

{\bf Theorem~5.11:} Any page replacement algorithm, online or offline,
can be modified to be demand paging without increasing the overall
cost on any request sequence.
\end{frame}

\begin{frame}
\begin{center}
\begin{minipage}{8cm}
\xymatrix@C=5mm{
&&\ar@{|=|}[rr]^c&&\ar@{|=|}[r]^d&&& \\
& \ar@{|=|}[rr]^a && \ar@{|=|}[rr]^b && && \\
\text{ALG} &&\times&&\times&&& \\
\text{ALG}' &&& \times\ar@{-}[ul] && \times\ar@{--}[ulll]\ar@{-}[ul] && \\
\sigma=&\sigma_1&\sigma_2&\sigma_i=p\ar@{.}[uuuu]&\bullet
&\sigma_j=p\ar@{.}[uuuu] &\sigma_n& \\
&&&&{\text{\begin{minipage}{2.8cm}\centering
\footnotesize $p$ is evicted from the cache of $\ALG'$
\end{minipage}}}\ar[u]&&&
}
\end{minipage}
\end{center}
\end{frame}

\begin{frame}
Suppose that $i,j$ is the smallest pair such that there
exists a page $p$ with the property that $\sigma_i=\sigma_j=p$.
$\ALG'$ incurs a page fault at $\sigma_i$ and $\sigma_j$, and the two
corresponding page moves of $\ALG'$ are both matched with the same
page move of $p$ by $\ALG$ somewhere in the stretch $a$.  

We show that
this is not possible: if $\ALG'$ incurs a page fault at
$\sigma_i=\sigma_j=p$ it means that somewhere in $b$
the page $p$ is evicted---this point is denoted with
`$\bullet$'.  

If $\ALG$ did not evict $p$ in the stretch $c$, then
$\ALG$ also evicts page $p$ at `$\bullet$' and so it must then bring it
back to the cache in stretch $d$---we would match the $\times$ at
$\sigma_j$ with that move.  

If $\ALG$ did evict $p$ in the stretch
$c$, then again it would have to bring it back in before $\sigma_j$.
In any case, there is a later move of $p$ that would be matched with
the page fault of $\ALG'$ at $\sigma_j$.
\end{frame}

\begin{frame}
{FIFO}

When a page must be replaced, the {\em oldest} page is chosen.  It is
not necessary to record the time when a page was brought in; all we
need to do is create a $\FIFO$ (First-In/First-Out) queue to hold all
pages in memory.  

The $\FIFO$ algorithm is easy to understand and program, but its
performance is not good in general.

$\FIFO$ also suffers from the so called {\em Belady's
anomaly}.  Suppose that we have the following
sequence of page requests: $1,2,3,4,1,2,5,1,2,3,4,5$.  Then, we have
more page faults when $k=4$ than when $k=3$.  That is, FIFO has more
page faults with a bigger cache!
\end{frame}

\begin{frame}
{LRU}

If we use the recent past as an approximation of the near future, then
we will replace the page that {\em has not been used for the longest
period of time}.  This approach is the {\em Least Recently Used (LRU)}
algorithm.

$\LRU$ replacement associates with each page the time of that page's
last use.  When a page must be replaced, $\LRU$ chooses that page that
has not been used for the longest period of time.  The $\LRU$
algorithm is considered to be good, and is often implemented---the
major problem is {\em how} to implement it;  two typical solutions are
counters and stacks.
\end{frame}

\end{document}
